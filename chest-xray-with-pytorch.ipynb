{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Pneumonia Classification with PyTorch","metadata":{}},{"cell_type":"markdown","source":"## Data Understanding","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2021-12-21T23:04:03.339220Z","iopub.execute_input":"2021-12-21T23:04:03.339905Z","iopub.status.idle":"2021-12-21T23:04:04.400210Z","shell.execute_reply.started":"2021-12-21T23:04:03.339785Z","shell.execute_reply":"2021-12-21T23:04:04.399511Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Let's visualize two images for each categoric, which is a normal lung(NORMAL) and a lung with some type of bacteria or infection(Pneumonia)\ndata_dir = ('../input/chest-xray-pneumonia/chest_xray/train')\ncategories = ['NORMAL', 'PNEUMONIA']\nfor i in categories:\n    path = os.path.join(data_dir, i)\n    num = 0\n    for img in os.listdir(path):\n        if num != 2:\n            img_array = cv2.imread(os.path.join(path,img))\n            img_array = cv2.resize(img_array, (250, 250))\n            plt.imshow(img_array)\n            plt.title(i)\n            plt.show()\n            num +=1\n        else:\n            break\n            \n","metadata":{"execution":{"iopub.status.busy":"2021-12-21T23:04:04.402656Z","iopub.execute_input":"2021-12-21T23:04:04.403105Z","iopub.status.idle":"2021-12-21T23:04:05.432987Z","shell.execute_reply.started":"2021-12-21T23:04:04.403067Z","shell.execute_reply":"2021-12-21T23:04:05.432331Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Now, let's see the shape of the one image\nimage_files = os.listdir(path)\nimage = os.path.join(path, image_files[0])\nimage = cv2.imread(image)\nimage.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-21T23:04:05.434138Z","iopub.execute_input":"2021-12-21T23:04:05.434897Z","iopub.status.idle":"2021-12-21T23:04:05.449921Z","shell.execute_reply.started":"2021-12-21T23:04:05.434839Z","shell.execute_reply":"2021-12-21T23:04:05.449277Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"code","source":"\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom torchvision import transforms\nimport torch \nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torchvision.datasets as dsets\nfrom PIL import Image\n\n# For the same results everytime we need to run this code\ntorch.manual_seed(0)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T23:04:05.451891Z","iopub.execute_input":"2021-12-21T23:04:05.452345Z","iopub.status.idle":"2021-12-21T23:04:07.138414Z","shell.execute_reply.started":"2021-12-21T23:04:05.452311Z","shell.execute_reply":"2021-12-21T23:04:07.137785Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Are GPU Avaible?\ntorch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T23:04:07.139825Z","iopub.execute_input":"2021-12-21T23:04:07.140072Z","iopub.status.idle":"2021-12-21T23:04:07.184512Z","shell.execute_reply.started":"2021-12-21T23:04:07.140039Z","shell.execute_reply":"2021-12-21T23:04:07.183771Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Creating a variable with the gpu, it will be needed later\ndevice = torch.device('cuda:0')","metadata":{"execution":{"iopub.status.busy":"2021-12-21T23:04:07.185981Z","iopub.execute_input":"2021-12-21T23:04:07.186600Z","iopub.status.idle":"2021-12-21T23:04:07.191919Z","shell.execute_reply.started":"2021-12-21T23:04:07.186536Z","shell.execute_reply":"2021-12-21T23:04:07.191146Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Saving the path to the normal files \nnormal = \"NORMAL\"\nnormal_path = os.path.join(data_dir, normal)\nnormal_files = [os.path.join(normal_path,file) for file in  os.listdir(normal_path) if file.endswith(\".jpeg\")]\nnormal_files.sort()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T23:04:07.193531Z","iopub.execute_input":"2021-12-21T23:04:07.194063Z","iopub.status.idle":"2021-12-21T23:04:07.207685Z","shell.execute_reply.started":"2021-12-21T23:04:07.194019Z","shell.execute_reply":"2021-12-21T23:04:07.206867Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"normal_files[0]","metadata":{"execution":{"iopub.status.busy":"2021-12-21T23:04:07.209579Z","iopub.execute_input":"2021-12-21T23:04:07.210309Z","iopub.status.idle":"2021-12-21T23:04:07.216372Z","shell.execute_reply.started":"2021-12-21T23:04:07.210269Z","shell.execute_reply":"2021-12-21T23:04:07.215354Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Saving the path to the pneumonia files \npneu = \"PNEUMONIA\"\npneu_path = os.path.join(data_dir, pneu)\npneu_files = [os.path.join(pneu_path,file) for file in  os.listdir(pneu_path) if file.endswith(\".jpeg\")]\npneu_files.sort()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T23:04:07.218167Z","iopub.execute_input":"2021-12-21T23:04:07.218561Z","iopub.status.idle":"2021-12-21T23:04:07.236765Z","shell.execute_reply.started":"2021-12-21T23:04:07.218525Z","shell.execute_reply":"2021-12-21T23:04:07.236097Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"pneu_files[0:5]","metadata":{"execution":{"iopub.status.busy":"2021-12-21T23:04:07.240192Z","iopub.execute_input":"2021-12-21T23:04:07.240407Z","iopub.status.idle":"2021-12-21T23:04:07.246783Z","shell.execute_reply.started":"2021-12-21T23:04:07.240380Z","shell.execute_reply":"2021-12-21T23:04:07.245025Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# We have 5216 files\nnumber_of_samples = len(normal_files) + len(pneu_files)\nnumber_of_samples","metadata":{"execution":{"iopub.status.busy":"2021-12-21T23:04:07.248639Z","iopub.execute_input":"2021-12-21T23:04:07.248963Z","iopub.status.idle":"2021-12-21T23:04:07.255620Z","shell.execute_reply.started":"2021-12-21T23:04:07.248927Z","shell.execute_reply":"2021-12-21T23:04:07.254783Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Creating a long tensor that will contain the labels.\nY=torch.zeros([number_of_samples])\nY=Y.type(torch.LongTensor)\nY.type()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T23:04:07.257452Z","iopub.execute_input":"2021-12-21T23:04:07.258064Z","iopub.status.idle":"2021-12-21T23:04:07.279931Z","shell.execute_reply.started":"2021-12-21T23:04:07.258024Z","shell.execute_reply":"2021-12-21T23:04:07.279160Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# There are 1341 normal files, after that, all files are pneumonia ones.\n# So i'm creating the labels here, were 0 is normal files(file 1 to 1341) and 1 is the pneumonia files(file 1341 to 5216)\nY[:1341] = 0\nY[1341:]= 1\n","metadata":{"execution":{"iopub.status.busy":"2021-12-21T23:04:07.289191Z","iopub.execute_input":"2021-12-21T23:04:07.289513Z","iopub.status.idle":"2021-12-21T23:04:07.304970Z","shell.execute_reply.started":"2021-12-21T23:04:07.289409Z","shell.execute_reply":"2021-12-21T23:04:07.304011Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Join the files\nall_files = normal_files + pneu_files\n","metadata":{"execution":{"iopub.status.busy":"2021-12-21T23:04:07.306075Z","iopub.execute_input":"2021-12-21T23:04:07.308801Z","iopub.status.idle":"2021-12-21T23:04:07.314254Z","shell.execute_reply.started":"2021-12-21T23:04:07.308761Z","shell.execute_reply":"2021-12-21T23:04:07.313410Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# See the results here\nall_files[1339:1345]","metadata":{"execution":{"iopub.status.busy":"2021-12-21T23:04:07.315934Z","iopub.execute_input":"2021-12-21T23:04:07.316340Z","iopub.status.idle":"2021-12-21T23:04:07.323993Z","shell.execute_reply.started":"2021-12-21T23:04:07.316296Z","shell.execute_reply":"2021-12-21T23:04:07.322986Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# And the labels are correct\nY.tolist()[1339:1345]","metadata":{"execution":{"iopub.status.busy":"2021-12-21T23:04:07.325789Z","iopub.execute_input":"2021-12-21T23:04:07.326166Z","iopub.status.idle":"2021-12-21T23:04:07.333222Z","shell.execute_reply.started":"2021-12-21T23:04:07.326127Z","shell.execute_reply":"2021-12-21T23:04:07.332502Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# For some better understanding, let's see the files with their paths and labesl\nfor y,file in zip(Y.tolist()[1339:1345], all_files[1339:1345]):\n    print(file)\n    plt.imshow(cv2.imread(file))\n    plt.title(\"y=\"+str(y))\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T23:04:07.334725Z","iopub.execute_input":"2021-12-21T23:04:07.335573Z","iopub.status.idle":"2021-12-21T23:04:09.471309Z","shell.execute_reply.started":"2021-12-21T23:04:07.335533Z","shell.execute_reply":"2021-12-21T23:04:09.470648Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Data Preparation\nI'm gonna creat a class named \"Dataset\", that will have the exactly same process above, and than we are gonna to pass it to the data loader.","metadata":{}},{"cell_type":"code","source":"class Dataset(Dataset):\n\n    # Constructor\n    def __init__(self,transform=None, train=True):\n        # The training data\n        if train:\n            directory= \"../input/chest-xray-pneumonia/chest_xray/train\"\n            normal = \"NORMAL\"\n            pneu = \"PNEUMONIA\"\n\n            normal_file_path = os.path.join(directory,normal)\n            pneu_file_path = os.path.join(directory,pneu)\n\n            normal_files = [os.path.join(normal_file_path,file) for file in  os.listdir(normal_file_path) if file.endswith(\".jpeg\")]\n            normal_files.sort()\n\n            pneu_files = [os.path.join(pneu_file_path,file) for file in  os.listdir(pneu_file_path) if file.endswith(\".jpeg\")]\n            pneu_files.sort()\n\n            number_of_samples = len(normal_files) + len(pneu_files)\n\n            all_files = [None]*number_of_samples\n            all_files[:len(normal_files)] = normal_files\n            all_files[len(normal_files):] = pneu_files\n            self.all_files = all_files\n            \n            # Saving the lenght\n            self.len = len(self.all_files)\n            \n            # The transform is goint to be used on image\n            self.transform = transform\n            \n            #torch.LongTensor with the labels\n            Y=torch.zeros([number_of_samples]).type(torch.LongTensor)\n            Y[:len(normal_files)] = 0\n            Y[len(normal_files):] = 1\n            self.Y = Y\n       \n    # validation data    \n        else:\n            directory= \"../input/chest-xray-pneumonia/chest_xray/test\"\n            normal = \"NORMAL\"\n            pneu = \"PNEUMONIA\"\n\n            normal_file_path = os.path.join(directory,normal)\n            pneu_file_path = os.path.join(directory,pneu)\n\n            normal_files = [os.path.join(normal_file_path,file) for file in  os.listdir(normal_file_path) if file.endswith(\".jpeg\")]\n            normal_files.sort()\n\n            pneu_files = [os.path.join(pneu_file_path,file) for file in  os.listdir(pneu_file_path) if file.endswith(\".jpeg\")]\n            pneu_files.sort()\n\n            number_of_samples = len(normal_files) + len(pneu_files)\n\n            all_files=[None]*number_of_samples\n            all_files[:len(normal_files)]= normal_files\n            all_files[len(normal_files):]= pneu_files\n            self.all_files = all_files\n            \n            # Saving the lenght\n            self.len = len(self.all_files)\n            \n            # The transform is goint to be used on image\n            self.transform = transform\n            #torch.LongTensor\n            Y=torch.zeros([number_of_samples]).type(torch.LongTensor)\n            Y[:len(normal_files)] = 0\n            Y[len(normal_files):] = 1\n            self.Y = Y\n\n\n\n        # Get the length\n    def __len__(self):\n        return self.len\n\n         # Getter\n    def __getitem__(self, idx):\n        \n        \n        image=Image.open(self.all_files[idx])\n        y=self.Y[idx]\n          \n        \n        # If there is any transform method, apply it onto the image\n        if self.transform:\n            image = self.transform(image)\n            \n            \n            \n            \n            \n\n        return image, y","metadata":{"execution":{"iopub.status.busy":"2021-12-21T23:04:09.472512Z","iopub.execute_input":"2021-12-21T23:04:09.473370Z","iopub.status.idle":"2021-12-21T23:04:09.490491Z","shell.execute_reply.started":"2021-12-21T23:04:09.473328Z","shell.execute_reply":"2021-12-21T23:04:09.489747Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# For the purpose of this code to run light, let's resize the images to 250x250. Also, the images are in different sizes, so we need to fix this.\nIMAGE_SIZE = 250\n\n\n# Composed function (Works as a pipeline for the transforms that we need make on the imagens)\n# For the normalizer, a already calculate the mean and std of the images. (Just one mean because I gonna grayscale the images, if I use RGB, it would need 3 mean and std, one for each channel)\ncomposed_train = transforms.Compose([transforms.Grayscale(num_output_channels=1), transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)), transforms.ToTensor(), transforms.Normalize(0.4823, 0.2363)])\ncomposed_test = transforms.Compose([transforms.Grayscale(num_output_channels=1), transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)), transforms.ToTensor(), transforms.Normalize(0.4747, 0.2361)])","metadata":{"execution":{"iopub.status.busy":"2021-12-21T23:04:09.491999Z","iopub.execute_input":"2021-12-21T23:04:09.492298Z","iopub.status.idle":"2021-12-21T23:04:09.502166Z","shell.execute_reply.started":"2021-12-21T23:04:09.492223Z","shell.execute_reply":"2021-12-21T23:04:09.501400Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Creating the datasets through the class\ndataset_train = Dataset(transform=composed_train,train=True)\ndataset_val = Dataset(transform=composed_test,train=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T23:04:09.503246Z","iopub.execute_input":"2021-12-21T23:04:09.503612Z","iopub.status.idle":"2021-12-21T23:04:09.558526Z","shell.execute_reply.started":"2021-12-21T23:04:09.503576Z","shell.execute_reply":"2021-12-21T23:04:09.557804Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Position 0 is the imagens\ndataset_train[0][0].shape","metadata":{"execution":{"iopub.status.busy":"2021-12-21T23:04:09.561454Z","iopub.execute_input":"2021-12-21T23:04:09.561667Z","iopub.status.idle":"2021-12-21T23:04:09.674191Z","shell.execute_reply.started":"2021-12-21T23:04:09.561643Z","shell.execute_reply":"2021-12-21T23:04:09.673490Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# The dataloaders for the model.\n# only batch size of 32 run in this code, others sizes like 64 or plus gets CUDA error (Lack of memory)\ntrain_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=32, shuffle=True, num_workers=1)\ntest_loader = torch.utils.data.DataLoader(dataset=dataset_val, batch_size=32, shuffle=True, num_workers=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T23:04:09.675384Z","iopub.execute_input":"2021-12-21T23:04:09.675733Z","iopub.status.idle":"2021-12-21T23:04:09.681045Z","shell.execute_reply.started":"2021-12-21T23:04:09.675695Z","shell.execute_reply":"2021-12-21T23:04:09.680056Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# Modelling","metadata":{"jupyter":{"outputs_hidden":true}}},{"cell_type":"code","source":"import torch.nn as nn\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2021-12-21T23:04:09.682588Z","iopub.execute_input":"2021-12-21T23:04:09.683062Z","iopub.status.idle":"2021-12-21T23:04:09.689820Z","shell.execute_reply.started":"2021-12-21T23:04:09.683006Z","shell.execute_reply":"2021-12-21T23:04:09.689122Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Creating my PyTorch model.\n# The class has to inherit it's functions from pytorch's nn.Module class\nclass CNN(nn.Module):\n    \n    # Contructor\n    def __init__(self):\n        super(CNN, self).__init__()\n        # Conv1\n        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=5, stride=1, padding=0)\n        self.conv1_bn = nn.BatchNorm2d(64)\n        self.maxpool1=nn.MaxPool2d(kernel_size=2, stride=2)\n        \n        # Conv2\n        self.cnn2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5,stride=1, padding=0)\n        self.conv2_bn = nn.BatchNorm2d(128)\n        self.maxpool2=nn.MaxPool2d(kernel_size=2, stride=1)  \n        \n        # Conv3\n        self.cnn3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=5,stride=1, padding=0)\n        self.conv3_bn = nn.BatchNorm2d(256)\n        self.maxpool3=nn.MaxPool2d(kernel_size=2, stride=2)\n        \n        # Conv4\n        self.cnn4 = nn.Conv2d(in_channels=256, out_channels=128, kernel_size=5,stride=1, padding=0)\n        self.conv4_bn = nn.BatchNorm2d(128)\n        self.maxpool4=nn.MaxPool2d(kernel_size=2, stride=1)\n        \n        # Conv5\n        self.cnn5 = nn.Conv2d(in_channels=128, out_channels=32, kernel_size=5,stride=1, padding=0)\n        self.conv5_bn = nn.BatchNorm2d(32)\n        self.maxpool5=nn.MaxPool2d(kernel_size=2, stride=2)\n        \n      \n        # Fully connected layer 1\n        self.drop_out1 = nn.Dropout(0.2)\n        self.fc1 = nn.Linear(in_features=32 * 24 * 24, out_features=500)\n        self.bn_fc1 = nn.BatchNorm1d(500)\n        \n         # Fully connected layer 2\n        self.drop_out2 = nn.Dropout(0.2)\n        self.fc2 = nn.Linear(in_features=500, out_features=1000)\n        self.bn_fc2 = nn.BatchNorm1d(1000)\n        \n         # Fully connected layer 3\n        self.drop_out3 = nn.Dropout(0.2)\n        self.fc3 = nn.Linear(in_features=1000, out_features=1000)\n        self.bn_fc3 = nn.BatchNorm1d(1000)\n        \n         # Fully connected layer 4\n        self.drop_out4 = nn.Dropout(0.2)\n        self.fc4 = nn.Linear(in_features=1000, out_features=500)\n        self.bn_fc4 = nn.BatchNorm1d(500)\n        \n         # Fully connected layer 5\n        self.drop_out5 = nn.Dropout(0.2)\n        self.fc5 = nn.Linear(in_features=500, out_features=250)\n        self.bn_fc5 = nn.BatchNorm1d(250)\n        \n         # Fully connected layer 6 \n        self.fc6 = nn.Linear(in_features=250, out_features=2)\n        \n    \n        \n    \n    # For Prediction\n    def forward(self, x):\n        # conv1\n        x = self.cnn1(x)\n        x = self.conv1_bn(x)\n        x = torch.relu(x)\n        x = self.maxpool1(x)\n        # conv2\n        x = self.cnn2(x)\n        x = self.conv2_bn(x)\n        x = torch.relu(x)\n        x = self.maxpool2(x)\n        # conv3\n        x = self.cnn3(x)\n        x = self.conv3_bn(x)\n        x = torch.relu(x)\n        x = self.maxpool3(x)\n        # conv4\n        x = self.cnn4(x)\n        x = self.conv4_bn(x)\n        x = torch.relu(x)\n        x = self.maxpool4(x)\n        # conv5\n        x = self.cnn5(x)\n        x = self.conv5_bn(x)\n        x = torch.relu(x)\n        x = self.maxpool5(x)\n        \n        # Fcl1\n        x = x.view(x.size(0), -1)\n        x = self.drop_out1(x)\n        x = self.fc1(x)\n        x = self.bn_fc1(x)\n        x = torch.relu(x)\n        # Fcl2\n        x = self.drop_out2(x)\n        x = self.fc2(x)\n        x = self.bn_fc2(x)\n        x = torch.relu(x)\n        # Fcl3\n        x = self.drop_out3(x)\n        x = self.fc3(x)\n        x = self.bn_fc3(x)\n        x = torch.relu(x)\n        # Fcl4\n        x = self.drop_out4(x)\n        x = self.fc4(x)\n        x = self.bn_fc4(x)\n        x = torch.relu(x)\n        # Fcl5\n        x = self.drop_out5(x)\n        x = self.fc5(x)\n        x = self.bn_fc5(x)\n        x = torch.relu(x)\n        # final fcl\n        x = self.fc6(x)\n        #x = torch.sigmoid(x)\n       \n        return x","metadata":{"execution":{"iopub.status.busy":"2021-12-21T23:04:09.691395Z","iopub.execute_input":"2021-12-21T23:04:09.691896Z","iopub.status.idle":"2021-12-21T23:04:09.716435Z","shell.execute_reply.started":"2021-12-21T23:04:09.691859Z","shell.execute_reply":"2021-12-21T23:04:09.715639Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# The training function\ndef train_model(model,train_loader,test_loader,optimizer,n_epochs=100):\n    \n    # For computing the accuracy and loss\n    N_test=len(dataset_val)\n    accuracy_list=[]\n    loss_list=[]\n    \n    for epoch in range(n_epochs):\n        cost = 0\n        model.train()\n        print(f\"Epoch: {epoch + 1}\")\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)   # passing the variables to gpu\n            \n            optimizer.zero_grad()  # resetting the gradient\n            z = model(x)           # Fiting the data\n            #y = y.unsqueeze(-1)    # in case of we use BCELoss as criterion\n            #y = y.float()\n            loss = criterion(z, y)   # Passing to the loss funtion with Cross Entropy\n            \n            loss.backward()    # backpropagation\n            optimizer.step()   # updating the weights\n           \n            cost+=loss.item()   \n\n        correct=0\n        model.eval()\n        #perform a prediction on the validation  data  \n        for x_test, y_test in test_loader:\n            x_test, y_test = x_test.to(device), y_test.to(device)  # passing the variables to gpu\n            \n            z = model(x_test)                  # making a prediction\n            _, yhat = torch.max(z.data, 1)     # threshold\n            correct += (yhat == y_test).sum().item()      # Saving the corrects predictions\n        accuracy = correct / N_test                       # Getting the accuracy\n        print(f\"correct: {correct}, N_test: {N_test}\")\n        accuracy_list.append(accuracy)\n        loss_list.append(cost)\n        print(f\"------>  loss: {round(cost, 8)}, accuracy_val: %{accuracy * 100}\")\n    \n     \n    return accuracy_list, loss_list","metadata":{"execution":{"iopub.status.busy":"2021-12-21T23:04:09.718043Z","iopub.execute_input":"2021-12-21T23:04:09.718552Z","iopub.status.idle":"2021-12-21T23:04:09.729620Z","shell.execute_reply.started":"2021-12-21T23:04:09.718513Z","shell.execute_reply":"2021-12-21T23:04:09.728883Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Creating the model and passing it to the gpu\nmodel = CNN()\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T23:04:09.731168Z","iopub.execute_input":"2021-12-21T23:04:09.731666Z","iopub.status.idle":"2021-12-21T23:04:12.855064Z","shell.execute_reply.started":"2021-12-21T23:04:09.731628Z","shell.execute_reply":"2021-12-21T23:04:12.854317Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\nlearning_rate = 0.001\noptimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T23:37:30.890846Z","iopub.execute_input":"2021-12-21T23:37:30.891137Z","iopub.status.idle":"2021-12-21T23:37:30.897017Z","shell.execute_reply.started":"2021-12-21T23:37:30.891104Z","shell.execute_reply":"2021-12-21T23:37:30.896242Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Training the model for 10 epochs\naccuracy_list, loss_list = train_model(model=model,n_epochs=10, train_loader=train_loader,test_loader = test_loader,optimizer=optimizer)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T23:37:36.202607Z","iopub.execute_input":"2021-12-21T23:37:36.203159Z","iopub.status.idle":"2021-12-21T23:52:33.241043Z","shell.execute_reply.started":"2021-12-21T23:37:36.203121Z","shell.execute_reply":"2021-12-21T23:52:33.239393Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation\n\n","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig, ax1 = plt.subplots()\ncolor = 'tab:red'\nax1.plot(loss_list, color=color)\nax1.set_xlabel('epoch', color=color)\nax1.set_ylabel('Loss', color=color)\nax1.tick_params(axis='y', color=color)\n    \nax2 = ax1.twinx()  \ncolor = 'tab:blue'\nax2.set_ylabel('Accuracy', color=color) \nax2.set_xlabel('epoch', color=color)\nax2.plot( accuracy_list, color=color)\nax2.tick_params(axis='y', color=color)\nfig.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-12-22T00:22:53.577044Z","iopub.execute_input":"2021-12-22T00:22:53.577289Z","iopub.status.idle":"2021-12-22T00:22:53.892048Z","shell.execute_reply.started":"2021-12-22T00:22:53.577263Z","shell.execute_reply":"2021-12-22T00:22:53.891372Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}